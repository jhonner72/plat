package com.fxa.nab.dctm.migration;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileFilter;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.ResourceBundle;

import org.apache.log4j.Logger;
import com.documentum.com.DfClientX;
import com.documentum.com.IDfClientX;
import com.documentum.fc.client.IDfACL;
import com.documentum.fc.client.IDfClient;
import com.documentum.fc.client.IDfFolder;
import com.documentum.fc.client.IDfSession;
import com.documentum.fc.client.IDfSessionManager;
import com.documentum.fc.client.IDfBatchManager;
import com.documentum.fc.client.IDfSysObject;
import com.documentum.fc.common.DfException;
import com.documentum.fc.common.DfLogger;
import com.documentum.fc.common.DfTime;
import com.documentum.fc.common.IDfLoginInfo;
import com.documentum.fc.common.IDfTime;

/**
 * This program is to Bulk Migrate Cheque images in 'batches' from FISERV to FXA as follows :
 * #) Read the 'ingestion.properties' file.
 * #) Read the batch folders (subject to 'total_batch_to_process' property)
 * #) Pick one folder at a time, read the csv file and check for errors.
 * #) If error, move the folder to 'failed_batch_location' location and pick another folder.
 * #) If no error, read the csv file and create one NABHistoricalDoc and multiple NABHistoricalCheque doc. NABHistoricalCheque depends on the no of images.
 * 
 * Assumptions and conventions:
 * #) csv file doesn't have headers.
 * #) The file format of the images are tiff.
 * #) Every batch folders are unique.
 * #) All batch folder to be processed will be copied to pickup location.
 * #) All cheques and deposit slip belongs to a transaction 'always' available in the same batch/csv file.
 * #) All files belonged to a batch MUST be processed as a single transaction. It means, a single tampered image or mandatory missing properties will result 
 * in the failure of whole batch.
 * #) In the batch/csv file, all the vouchers belonged to a particular transaction will be in sequence.
 * 
 * 
 * Queries:
 * 1) Naming convention for csv file
 * 2) Properties name mapping between csv and Dctm Repository.
 * 3) Log file naming convention.
 * 4) Does the front and back page of a cheque comes as a single file or two seperate files. If not, how do we relate front and back side of an cheque.
 * 5) What is the naming convention for zip folder name and csv file? which one of them will be unique?
 * 6) What is an 'Entry', 'batch','balanced deposit', 'sequence no of balance deposit', 'item sequence no' in the csv file and how they are inter-related.
 * 7) Does the same 'Entry' number representing a balanced transaction is Unique for the whole historical data? 
 *
 * Validation:
 * 1) reference_number (DRN), Classification, amount, entry,  cannot be null.
 * 2) Validation Test
 * 
 * 
 * 
 * Sample Properties File 'ingestion.properties':
		login_user_dctm=""
		password_encrypted=
		
		pickup_location=""
		target_dctm_location=""
		failed_batch_location=""
		
		log_location=""
		log_dctm_location=
		
		shareable_object_type=""
		lightweight_object_type=""
		acl=""
		
		total_batch_to_process=""
 *
 * 
 * Phase2 Queries:
 * 1) In section 1.5, point 3 contradicts with point 6. Multiple zip files with the same name?
2) 2 checksum for Backload and 1 checksum for Daily Production images?
3) Can we have a sample of automated text report generated by FISERV. This will help us to understand the report format and to write program if necessary to parse it for reconciliation purpose..

Assumptions:
1) The data received in SFTP or Hard drive transfer will be processed and copied to pick up location by ?
2) 

Queries and answers from FISERV: 

Front and Back of cheque images: 

1. Do the front and back image of a cheque always come as a single file? Yes, refer section 3.1, 4th bullet point 
2. If no to Q1 - that is front and back image come as two separate files: Will they always be specified as one entry (line) in the CSV file? NA 

3. If no to Q2 - that is front and back image appear on two separate LINES in the csv file: How can we link them as one cheque? NA 
Transaction 

4. How do we find a transaction using the columns 13, 14, 15 & 16 (entry, batch, seq no, item seq no) in the CSV file? Can you please provide us an example? Refer section 3.2 

5. Will the Dr and Cr forming a transaction always be within the same csv and zip file? YES, Refer 1.5, # 3 
6. Will the Dr and Cr forming a transaction always appear in sequence in the csv file? Refer 3.1, field 15 
7. Will 'Entry Number' (column 13 in csv file) be unique across all transactions? That is - will two different transactions (may be from different batches) can have the same entry number 
There are multiple Batches within the same entry. 
There are multiple transactions within the Batch. 
Fields 13,14,15 &16 combination make an item unique. 
Fields 13,14,15 combination make the transaction unique. 
CSV and Zip Files 

8. Checksum: What application do we need to use to calculate the checksum? Refer 3.1, fields 17 and 18. 2 different types of checksums applied. 

9. Checksum: Will this be added as a column in the csv file? Yes, 2 fields. Refer 3.1, fields 17 and 18 

10. Is there a chance of the same image occurring in a different line with different metadata? No. This would have been an error in original processing. 

11. What is the naming convention for the zip file? Refer 3.1, 4th bullet point 
Can we make it unique - so that, we can treat it as a batch number? Yes, it is Fiserv processing date. This is unique. 
Is it possible to make the CSV file have the same name as the zip file? Yes, it will be. It is the Fiserv processing date. This is unique. 
12. Can we assume the csv file will have no header line? Yes. Refer 3.1, 1st bullet point 
13. Can we assumer all the images are going to be tiff? (Design doc does say it will be) Yes 

14. What is the average size of each image? Refer 1.5, number 5 
 * */

public class BulkMigratorUsingCSV implements IBulkMigrator {
	
	static Logger logger=Logger.getLogger("BM_CSV_Logger");
		
	public static final String PROP_FILE="ingestion_csv";
	public static final String PATH_SEP="\\";
	public static final String CSV_SEP=",";
	public static final String CSV_EXT=".csv";
	
	public static final String login_user_key="login_user_dctm";
	public static final String password_encrypted_key="password_encrypted";	
	public static final String repository_name_key="repository_name";

	public static final String pickup_location_key="pickup_location";
	public static final String target_dctm_location_key="target_dctm_location";
	public static final String fail_batch_location_key="failed_batch_location";	
	
	public static final String log_location_key="log_location";
	public static final String log_dctm_location_key="log_dctm_location";
	
	public static final String object_type_key="object_type";
	public static final String lwobject_type_key="lightweight_object_type";
	public static final String acl_key="acl";

	public static final String total_batch_to_process_key="total_batch_to_process";

	
	private String login_user_val=null;
	private String password_encrypted_val=null;	
	private String repository_name_val=null;

	private String pickup_location_val=null;
	private String target_dctm_location_val=null;
	private String fail_batch_location_val=null;	
	
	private String log_location_val=null;
	private String log_dctm_location_val=null;
	
	private String object_type=null;
	private String lwobject_type_val=null;
	private String acl_val=null;

	private String total_batch_to_process_val=null;
	
	//Default Values
	private String login_user_default="dmadmin";
	private String password_encrypted_default="AAAAELQCUMM/GxUhz0Mpho1BNxWEDRCzZq2IekNLSfuW6JVY";
	private String repository_name_default="NAB";

	private String pickup_location_default="";
	private String target_dctm_location_default="/vouchers";
	private String fail_batch_location_default="";	
	
	private String log_location_default="";
	private String log_dctm_location_default="";
	
	private String object_type_default="fxa_voucher";
	private String lwobject_type_default="nab_historical_cheque";
	private String acl_default="nab_historical_acl";

	private String total_batch_to_process_default="20";	
	
	private boolean commandLineRun=false;

	public static final int debug=0;
	public static final int info=1;
	public static final int warn=2;
	public static final int error=3;
	
	IDfSessionManager sMgr;
	IDfSession session;
	
	public static IDfACL folderACLObj=null;
	public static IDfACL voucherACLObj=null;
	
	
	public void initAndProcess() throws Exception{
		writeToLog("Inside initAndProcess()..",debug,null);
		commandLineRun=true;
//		initLog();
		readProps();
//		checksum();
//		auditing();
//		batchValidation();
//		exceptionHandling();
//		createSession();
		
		
		File[] batchesToProcess=getBatchFolders();
		if(batchesToProcess.length < 1){
			String message="There are no batches to process. Bye!!";
			writeToLog(message,debug,null);
			return;
		}
		
		int tobeprocessed=0;
		if(batchesToProcess.length < Integer.parseInt(total_batch_to_process_val)){
			tobeprocessed=batchesToProcess.length;
		}else{
			tobeprocessed=Integer.parseInt(total_batch_to_process_val);
		}
		
		writeToLog(tobeprocessed+" batches will be processed for this run.",debug,null);
		
		HashMap<String,String> transactionAndDRN;
		for(int count=0;count<tobeprocessed;count++){
			writeToLog(batchesToProcess[count].getName(),debug,null);
			
			transactionAndDRN=new HashMap<String,String>();
			ArrayList<FxaVoucher> docList = readCSVFile(batchesToProcess[count],transactionAndDRN);
			processVouchersInABatch(batchesToProcess[count],docList,transactionAndDRN);
		}		
	}
	
	private void readProps(){
		writeToLog("Inside readProps() method",debug,null);
		
		ResourceBundle bundle=ResourceBundle.getBundle(PROP_FILE);
		writeToLog("Reading Properties File :"+PROP_FILE+".properties",debug,null);
		
		if(bundle == null ){
			String msg="No properties file with the given name "+PROP_FILE+" found.";
			writeToLog(msg,error,new Exception());
		}
		
		login_user_val=bundle.getString(login_user_key);
		if(login_user_val == null || login_user_val.length() == 0){
			login_user_val=login_user_default;
		}
		this.writeToLog("login_user :"+login_user_val,debug,null);
		
		
		password_encrypted_val=bundle.getString(password_encrypted_key);
		if( password_encrypted_val== null || password_encrypted_val.length() == 0){
			password_encrypted_val=password_encrypted_default;
		}
		this.writeToLog("password_encrypted :"+password_encrypted_val,debug,null);
		
		repository_name_val=bundle.getString(repository_name_key);
		if( repository_name_val== null || repository_name_val.length() == 0){
			repository_name_val=repository_name_default;
		}
		this.writeToLog("repository_name :"+repository_name_val,debug,null);
				
		pickup_location_val=bundle.getString(pickup_location_key);
		if( pickup_location_val== null || pickup_location_val.length() == 0){
			pickup_location_val=pickup_location_default;
		}
		this.writeToLog("pickup_location :"+pickup_location_val,debug,null);			
		
		target_dctm_location_val=bundle.getString(target_dctm_location_key);
		if(target_dctm_location_val == null || target_dctm_location_val.length() == 0){
			target_dctm_location_val=target_dctm_location_default;
		}
		this.writeToLog("target_dctm_location :"+target_dctm_location_val,debug,null);			
		
		fail_batch_location_val=bundle.getString(fail_batch_location_key);
		if( fail_batch_location_val== null || fail_batch_location_val.length() == 0){
			fail_batch_location_val=fail_batch_location_default;
		}
			this.writeToLog("fail_batch_location :"+fail_batch_location_val,debug,null);			
		
		log_location_val=bundle.getString(log_location_key);
		if(log_location_val == null || log_location_val.length() == 0){
			log_location_val=log_location_default;
		}
			this.writeToLog("log_location :"+log_location_val,debug,null);			
				
		log_dctm_location_val=bundle.getString(log_dctm_location_key);
		if(log_dctm_location_val == null || log_dctm_location_val.length() == 0){
			log_dctm_location_val=log_dctm_location_default;
		}
		this.writeToLog("log_dctm_location :"+log_dctm_location_val,debug,null);			
				
		object_type=bundle.getString(object_type_key);
		if(object_type == null || object_type.length() == 0){
			object_type=object_type_default;
		}
		this.writeToLog("Shareable object_type :"+object_type,debug,null);			
				
		lwobject_type_val=bundle.getString(lwobject_type_key);
		if(lwobject_type_val == null || lwobject_type_val.length() == 0){
			lwobject_type_val=lwobject_type_default;
		}
		this.writeToLog("Lightweight object_type :"+lwobject_type_default,debug,null);			
				
		acl_val=bundle.getString(acl_key);
		if( acl_val== null || acl_val.length() == 0){
			acl_val=acl_default;
		}
		this.writeToLog("acl :"+acl_val,debug,null);			
		
		total_batch_to_process_val=bundle.getString(total_batch_to_process_key);

		if(total_batch_to_process_val == null || total_batch_to_process_val.length() == 0){
			total_batch_to_process_val=total_batch_to_process_default;
		}
		
		try{
			Integer.parseInt(total_batch_to_process_val);
			
		}catch(NumberFormatException e){
			String message="Value for key '"+total_batch_to_process_key+"' is not an integer. Assigning default value...";
			writeToLog(message,debug,null);
			total_batch_to_process_val=total_batch_to_process_default;
		}
		
		this.writeToLog("total_batch_to_process :"+total_batch_to_process_val,debug,null);			
		
	}
	
    
	 /**
     * 
     * This method is used to create a session for the repository.
     * 
     * @param  loginName as String,password as String,domain as String,docbaseName as String
     * @return IDfSession
     * @throws DfException
     */
    public IDfSession createSession(String loginName,String password,String domain,String docbaseName) throws Exception{
		this.writeToLog("Inside 'createSession' method",debug,null);

		IDfClientX clientx = new DfClientX();
		IDfClient client = clientx.getLocalClient();
	
		sMgr = client.newSessionManager();
		IDfLoginInfo loginInfoObj = clientx.getLoginInfo();
	
		loginInfoObj.setUser(loginName);
		loginInfoObj.setPassword(password);
		loginInfoObj.setDomain(domain);
	
		sMgr.setIdentity(docbaseName,loginInfoObj);
		session=sMgr.getSession(docbaseName);
		
		if(getSession() == null){
			writeToLog("Session is null.",error,null);
			throw new DfException("Session is null.");
		}
		
		this.writeToLog("leaving 'createSession' method",debug,null);
		
		return  getSession();// returns a IDfSession Object
	 }
    
    private IDfSession getSession() throws Exception{
    	return (session != null)?session:createSession(login_user_val, password_encrypted_val,null,repository_name_val);
    }
	
	private void writeToLog(String message,int level,Throwable e){
		System.out.println(message);
		if(commandLineRun){
			if(level == debug){
			logger.debug(message);
			}else if(level == info){
				logger.info(message);
			}else if(level == warn){
					logger.warn(message);
			}else{
				logger.error(message);
				if(e!=null){
					logger.error(e.getMessage());
					e.printStackTrace();
				}
			}
			
		}else{
			if(level == debug){
				DfLogger.debug(this,message,null,null);
			}else if(level == info){
				DfLogger.info(this,message,null,null);
			}else if(level == warn){
				DfLogger.warn(this,message,null,null);
			}else{
				DfLogger.debug(this,message,null,null);
				if(e!=null){
					DfLogger.error(this,e.getMessage(), null, null);
					e.printStackTrace();
				}
			}			
		}
	}
	
	//Read Folders
	private File[] getBatchFolders() throws Exception{
		File pickupLocation=new File(pickup_location_val);
		
		if(pickupLocation.isDirectory()){
			
			return pickupLocation.listFiles(new FileFilter(){
				public boolean accept(File pathName){
					return pathName.isDirectory();
				}
			});
			
		}else{
			//log and throw error
			String message="The Pickup Location property '"+pickup_location_key+"' is not a directory. Cannot continue further....";
			writeToLog(message,error,null);
			throw new Exception(message);
		}
	}
	
	//Read CSV File
	public ArrayList<FxaVoucher> readCSVFile(File batchFolder,HashMap<String,String> transactionAndDRN){
		
		ArrayList<FxaVoucher> docList=new ArrayList<FxaVoucher>();
		
		
		File[] csvFile=batchFolder.listFiles(new FileFilter(){
			public boolean accept(File pathName){
				return (pathName.getName().endsWith(CSV_EXT));
			}
		});
		//.getAbsolutePath()+PATH_SEP+batchFolder+".csv";
		BufferedReader br = null;
		String line = "";
		String transaction="";
		
		if(csvFile == null || csvFile.length == 0){
			//log error and move to next
			String message="No csv file found in batch folder "+batchFolder.getName()+". Skipping it...";
			writeToLog(message,error,null);
		}else if(csvFile.length != 1){
			String message="More than one csv file found in batch folder "+batchFolder.getName()+".";
			message="Csv files are :\n";
			for (int i=0;i<csvFile.length;i++)
				message+=csvFile[i].getName()+"\n";
				message+="Skipping it...";
			writeToLog(message,error,null);
		}else{
			String message="The csv file for batch folder "+batchFolder.getName()+" is "+csvFile[0].getName();
			writeToLog(message,debug,null);
	 
			try {
	 
			br = new BufferedReader(new FileReader(csvFile[0]));
			FxaVoucher cheque=null;
		
			while ((line = br.readLine()) != null) {
				StringBuffer messageBuf=new StringBuffer();	
				
			    // use comma as separator
				String[] docData=line.split(CSV_SEP);	
				writeToLog("docData.length    "+docData.length,debug,null);
				cheque=new FxaVoucher();
				cheque.setFxa_processing_date(docData[0]);
				messageBuf.append("nab_processing_date "+docData[0]+"\n");
				
				cheque.setObject_name(docData[1]);
				messageBuf.append("object_name "+docData[1]+"\n");
				
				cheque.setFxa_extra_aux_dom(docData[3]);
				messageBuf.append("nab_extra_aux_dom "+docData[3]+"\n");
				
				cheque.setFxa_aux_dom(docData[4]);
				messageBuf.append("nab_aux_dom "+docData[4]+"\n");
				
				cheque.setFxa_bsb(docData[5]);
				messageBuf.append("nab_bsb "+docData[5]+"\n");
				
				cheque.setFxa_account_number(docData[6]);
				messageBuf.append("nab_account_number "+docData[6]+"\n");
				
				cheque.setFxa_trancode(docData[7]);
				messageBuf.append("nab_trancode "+docData[7]+"\n");
				
				cheque.setFxa_amount(docData[8]);
				messageBuf.append("nab_amount "+docData[8]+"\n");
				
				cheque.setFxa_drn(docData[9]);
				messageBuf.append("nab_reference_number "+docData[9]+"\n");
				
				cheque.setFxa_classification(docData[10]);
				messageBuf.append("nab_classification "+docData[10]+"\n");
				
				cheque.setFxa_collecting_bsb(docData[11]);
				messageBuf.append("nab_collecting_bsb "+docData[11]+"\n");
				
				cheque.setFxa_m_entry_number(docData[12]);
				messageBuf.append("nab_entry_number "+docData[12]+"\n");
				
				cheque.setFxa_m_batch_number(docData[13]);
				messageBuf.append("nab_batch_number "+docData[13]+"\n");
				
				cheque.setFxa_m_bal_seq_for_deposit(docData[14]);
				messageBuf.append("nab_bal_seq_for_deposit "+docData[14]+"\n");
				
				cheque.setFxa_m_balanced_sequence(docData[15]);
				messageBuf.append("nab_balanced_sequence "+docData[15]+"\n");	
				
				transaction=docData[12]+"-"+docData[13]+"-"+docData[14];
				cheque.setTransaction(transaction);
				messageBuf.append("nab_transaction "+transaction+"\n");
				
				if(docData[10].equalsIgnoreCase("CR")){
					transactionAndDRN.put(transaction, docData[9]);
				}
				
				writeToLog(messageBuf.toString(),debug,null);
				
				docList.add(cheque); //adding the object to arraylist
				
			}
			
			writeToLog("Total number of documents for "+batchFolder.getName()+" is "+docList.size(),debug,null);
	 
			} catch (FileNotFoundException e) {
				e.printStackTrace();
			} catch (IOException e) {
				e.printStackTrace();
			} finally {
				if (br != null) {
					try {
						br.close();
					} catch (IOException e) {
						e.printStackTrace();
					}
			}
		 }
		}
//		System.out.println("Done");
		
		return docList;		
	}
	
	
	
	/*//auditing
	private RollingFileAppender createBatchSpecificLog(String batchName){
		
		writeToLog("Inside createBatchSpecificLog",debug,null);
		
		RollingFileAppender appender=null;
		 
	       try{
	        	File logFile=new File(this.log_location_val,batchName+".log");
	            appender=new RollingFileAppender(new SimpleLayout(),batchName+".log");
	            
//	       		appender.setLayout(new SimpleLayout());
//	       		appender.setFile(batchName+".log");
	    		writeToLog("Appender file is "+logFile.getAbsolutePath(),debug,null);

	            //The log file size is set to 100 KB (1024bytes * 100)
	            appender.setMaximumFileSize(102400);
	            
	            //The Maximum number of Backup files is 1000.
	            appender.setMaxBackupIndex(1);
	            logger.addAppender(appender);
	            
	            }catch(Exception e){
	            	writeToLog("Error while creating appender for batch "+batchName,this.error,e);
	            	return null;
	            }
	       
		writeToLog("Leaving createBatchSpecificLog",debug,null);	       
	       
		return appender;
	}
	

	//auditing
	private boolean closeBatchSpecificLog(RollingFileAppender appender,String batchName){
		
//		 RollingFileAppender appender=null;
		 
	       try{

	            logger.removeAppender(appender);
	            
	            }catch(Exception e){
	            	writeToLog("Error while removing appender for batch "+batchName,this.error,e);
	            	return false;
	            }
	       
		return true;
	}	*/
	

	
	//Upload Images	
	private void processVouchersInABatch(File batchFolder,ArrayList<FxaVoucher> lwDocList,HashMap<String,String> transactionAndDRN) throws Exception{
		
		writeToLog("Inside processVouchersInABatch() method",debug,null);
		
		String batchName=batchFolder.getName();
		
		String folderPath=checkExistenseOfFolders(target_dctm_location_val, batchName.substring(4,8), batchName.substring(8,10), batchName.substring(10,12), batchName.substring(13));
				
		writeToLog("Processing "+batchName, info, null);
		
//		RollingFileAppender appender=createBatchSpecificLog(batchName);
		
//		if(appender==null){writeToLog("Appender is null ",error,null);}

		
		FxaVoucher chequeObj=null;
//		IDfId shareObjId=null;
		
		IDfBatchManager bMgr=getSession().getBatchManager();
		bMgr.openBatch();
		
		for(int count=0;count<lwDocList.size();count++){	
			chequeObj=(FxaVoucher)lwDocList.get(count);
			
		IDfSysObject nab_historical_doc=(IDfSysObject)getSession().newObject(object_type);


		     nab_historical_doc.setObjectName(chequeObj.getObject_name());		
			 nab_historical_doc.setContentType("tiff"); //remove this hardcode later
			 nab_historical_doc.setString("fxa_migration_batch_no",batchName);

			 writeToLog("Processing Document  :"+chequeObj.getObject_name(),info,null);		
				
			 nab_historical_doc.setFile(batchFolder.getAbsolutePath()+PATH_SEP+chequeObj.getObject_name());
			 
			 nab_historical_doc.setString("fxa_account_number",chequeObj.getFxa_account_number());
			 nab_historical_doc.setString("fxa_amount",chequeObj.getFxa_amount());
			 nab_historical_doc.setString("fxa_aux_dom",chequeObj.getFxa_aux_dom());

			 nab_historical_doc.setString("fxa_bsb",chequeObj.getFxa_bsb());
			 nab_historical_doc.setString("fxa_classification",chequeObj.getFxa_classification());
			 nab_historical_doc.setString("fxa_collecting_bsb",chequeObj.getFxa_collecting_bsb());
			 
			 nab_historical_doc.setString("fxa_m_entry_number",chequeObj.getFxa_m_entry_number());
			 nab_historical_doc.setString("fxa_m_batch_number",chequeObj.getFxa_m_batch_number());
			 nab_historical_doc.setString("fxa_m_bal_seq_for_deposit",chequeObj.getFxa_m_bal_seq_for_deposit());
			 nab_historical_doc.setString("fxa_m_balanced_sequence",chequeObj.getFxa_m_balanced_sequence());
			 
			 if(transactionAndDRN.get(chequeObj.getTransaction()) != null)
				 nab_historical_doc.setString("fxa_m_cr_drn",transactionAndDRN.get(chequeObj.getTransaction()));
			 
			 nab_historical_doc.setString("fxa_extra_aux_dom",chequeObj.getFxa_extra_aux_dom());			 
			 IDfTime processTime=new DfTime(parseDate(chequeObj.getFxa_processing_date()),IDfTime.DF_TIME_PATTERN14);
			 
			 nab_historical_doc.setTime("fxa_processing_date",processTime);			 
			 nab_historical_doc.setString("fxa_drn",chequeObj.getFxa_drn());
			 nab_historical_doc.setString("fxa_trancode",chequeObj.getFxa_trancode());

			 nab_historical_doc.link(folderPath);
			 nab_historical_doc.setACL(getVoucherACL());
				
			 nab_historical_doc.save();
		}
				
		bMgr.closeBatch();	
//		this.closeBatchSpecificLog(appender, batchName);
	}
	
	private String parseDate(String rawDate){
		String formattedDate=rawDate.substring(6)+"/"+rawDate.substring(4,6)+"/"+rawDate.substring(0,4);
//		writeToLog(formattedDate,debug,null);
	    return formattedDate;
	}
	
    public String checkExistenseOfFolders(String parentFolderPath,String yearFolder,String monthFolder,String dayFolder,String entryNumber) throws Exception{
		
		try{
			if(parentFolderPath == null || parentFolderPath.trim().length() == 0){
			writeToLog("The path to store in Documentum is either null or empty string. In properties file, check the key '"+BMProperties.target_dctm_location_key+"' has a valid folder path.",error,null);
			throw new FXAException("Exception from 'checkExistenseOfFolders(....)' method. No folder exist with the given path '"+parentFolderPath+"'. In properties file, check the key '"+BMProperties.target_dctm_location_key+"' has a valid folder path.");
			}
			
			//get the parentFolder object. 
			IDfFolder parentFolderObj = (IDfFolder) getSession().getFolderByPath(parentFolderPath);
			
			//Log error if not and return
			if(parentFolderObj == null){
				writeToLog("No folder exist with the given path "+parentFolderPath,error,null);
				throw new FXAException("Exception from 'checkExistenseOfFolders(....)' method. No folder exist with the given path '"+parentFolderPath+"'. In properties file, check the key '"+BMProperties.target_dctm_location_key+"' has a valid folder path.");
			}
			
			checkEachAndCreate(yearFolder,parentFolderPath);
			String yearFolderPath=parentFolderPath.endsWith(BMProperties.DCTM_PATH_SEP)?parentFolderPath+yearFolder:parentFolderPath+BMProperties.DCTM_PATH_SEP+yearFolder;
			checkEachAndCreate(monthFolder,yearFolderPath);
			String monthFolderPath=yearFolderPath+BMProperties.DCTM_PATH_SEP+monthFolder;
			checkEachAndCreate(dayFolder,monthFolderPath);			
			String dayFolderPath=monthFolderPath+BMProperties.DCTM_PATH_SEP+dayFolder;
			checkEachAndCreate(entryNumber,dayFolderPath);	
			String entryFolderPath=dayFolderPath+BMProperties.DCTM_PATH_SEP+entryNumber;
			
			return entryFolderPath;
		
		}catch(DfException e){
			writeToLog("DfException from 'checkExistenseOfFolders(....)' method. DfException message is : \n "+e.getMessage(), error,null);
			e.printStackTrace();
			throw e;
		}catch(Exception e){
			writeToLog("Exception from 'checkExistenseOfFolders(....)' method. Exception message is : \n "+e.getMessage(), error,null);
			e.printStackTrace();
			throw e;
		}						
	}

	private void checkEachAndCreate(String folderName,String parentFolderPath) throws Exception{
		
		try{
		  String thisFolderPath=parentFolderPath.endsWith(BMProperties.DCTM_PATH_SEP)?parentFolderPath+folderName:parentFolderPath+BMProperties.DCTM_PATH_SEP+folderName;
		
		  IDfFolder thisFolderPathObj= (IDfFolder) getSession().getFolderByPath(thisFolderPath);
		  if(thisFolderPathObj == null){
				//if not exist, create it
			writeToLog("The folder with path "+thisFolderPath+" doesn't exist. Creating it.",debug,null);
				createFolder(parentFolderPath,folderName);
		  }else{
				//if exist, proceed
			writeToLog("The folder with year "+thisFolderPath+" already exist.",debug,null);
		  }
		}catch(DfException e){
			writeToLog("DfException from 'checkEachAndCreate(....)' method. DfException message is : \n "+e.getMessage(), error,null);
			e.printStackTrace();
			throw e;
		}catch(Exception e){
			writeToLog("Exception from 'checkEachAndCreate(....)' method. Exception message is : \n "+e.getMessage(), error,null);
			e.printStackTrace();
			throw e;
		}
	}


    private void createFolder(String parentFolder,String folderToBeCreated) throws Exception{
		
		try{
				IDfFolder folder = (IDfFolder) getSession().newObject("fxa_folder");
				folder.setObjectName(folderToBeCreated);
				
				if(getFolderACL() != null){
				 folder.setACL(getFolderACL());				
				}
				  
				folder.link(parentFolder);				
				folder.save();
				writeToLog(folderToBeCreated + " created under " + parentFolder,debug,null);
		}catch(DfException e){
			writeToLog("Exception from 'createFolder(...)' method. Exception message is : \n "+e.getMessage(), error,null);
		}
		
	}

   private IDfACL getFolderACL() throws Exception{
		
	try{
		if(folderACLObj != null){
			return folderACLObj;
		}else{
			String folderACLName="fxa_voucher_folder_acl";
			String folderACLDomain="dm_dbo";
			
			if(folderACLName != null && folderACLDomain != null){
				
				  folderACLObj=getACLObj(folderACLDomain,folderACLName);
				  if(folderACLObj != null){
					  	writeToLog("ACL for the folder is set as "+folderACLName+" and the ACL domain is "+folderACLDomain+".",debug,null);
						
					}else{
						writeToLog("ERROR : There is no ACL with the name "+folderACLName+" and domain "+folderACLDomain+".",debug,null);
						throw new FXAException("ERROR : There is no ACL with the name "+folderACLName+" and domain "+folderACLDomain+". Set correct folder acl and domain in properties file.");
					}
				}
			return folderACLObj;
		}
		
	 }catch(Exception e){
		 writeToLog("Exception from method getFolderACL(). Exception message is "+e.getMessage(),error,null);
		 throw e;
	 }		
    }
	
	public IDfACL getVoucherACL() throws Exception{
		
	try{
		if(voucherACLObj != null){
			return voucherACLObj;
		}else{
			String voucherACLName="fxa_voucher_acl";
			String voucherACLDomain="dm_dbo";
			
			if(voucherACLName != null && voucherACLDomain != null){
				
				  voucherACLObj=getACLObj(voucherACLDomain,voucherACLName);
				  if(voucherACLObj != null){
					  	writeToLog("ACL for the vouchers is set as "+voucherACLName+" and the ACL domain is "+voucherACLDomain+".",debug,null);
						
					}else{
						writeToLog("ERROR : There is no ACL with the name "+voucherACLName+" and domain "+voucherACLDomain+".",debug,null);
						throw new FXAException("ERROR : There is no ACL with the name "+voucherACLName+" and domain "+voucherACLDomain+". Set correct doc acl and domain in properties file.");
					}
				}
			return voucherACLObj;
		}
		
	 }catch(Exception e){
		 writeToLog("Exception from method getVoucherACL(). Exception message is "+e.getMessage(),error,null);
		 throw e;
	 }		
   }	

	public IDfACL getACLObj(String aclDomain,String aclName) throws Exception{
		
	try{
			IDfACL aclObj=null;
			if(aclDomain != null && aclName != null){
				writeToLog("aclDomain "+aclDomain,debug,null);
				writeToLog("aclName "+aclName,debug,null);
				
				aclObj=getSession().getACL(aclDomain,aclName);
				  if(aclObj != null){
					  writeToLog("ACL Object is not null",debug,null);
					  return aclObj;
				  }
				}
			writeToLog("ACL Object is NULL",debug,null);
			return null;
		
	 }catch(Exception e){
		 writeToLog("Exception from method getACLObj(). Exception message is "+e.getMessage(),error,null);
		 throw e;
	 }		
    }	
	
/*	private String processBalancedTransaction(FxaVoucher voucher,String[] cur_bal_trans_data){
	
		//Initialization or Construction of array
//		if(cur_bal_trans_data.length != 4){throw error;}
		
		//Assumption: if entry number is empty or null means other values must be null.
		if(cur_bal_trans_data[0] == null || cur_bal_trans_data[0].trim().isEmpty()){
			cur_bal_trans_data[0]=voucher.getEntry_number();
			cur_bal_trans_data[1]=voucher.getBatch_number();
			cur_bal_trans_data[2]=voucher.getBal_seq_for_deposit();
			cur_bal_trans_data[3]=voucher.getReference_number();
			return cur_bal_trans_data[3];
		}
		
		
		//Compare the entry_number,batch_number,balanced_sequence
		//if those matches, set the current cr drn as the cr_drn
		//otherwise update the array with new value
		if((voucher.getEntry_number().equals(cur_bal_trans_data[0])) &&  voucher.getBatch_number().equals(cur_bal_trans_data[1]) &&  voucher.getBal_seq_for_deposit().equals(cur_bal_trans_data[2])){
			return cur_bal_trans_data[3];			
		}else{
			cur_bal_trans_data[0]=voucher.getEntry_number();
			cur_bal_trans_data[1]=voucher.getBatch_number();
			cur_bal_trans_data[2]=voucher.getBal_seq_for_deposit();
			cur_bal_trans_data[3]=voucher.getReference_number();
			return cur_bal_trans_data[3];			
		}

	}*/

    
	public static void main( String[] args )
    {
        System.out.println( "Bulk Migration starts...." );
        BulkMigratorUsingCSV ingest=new BulkMigratorUsingCSV();
        try {
			ingest.initAndProcess();
			System.out.println("Vouchers uploaded successfully!!");
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
    }
}
